{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dMJxXG7OH_lo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting the images using import zipfile"
      ],
      "metadata": {
        "id": "VdddH8xQyCVK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qSl2JmyMUQsS"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/dataset-candidates-ml-jun.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data analysis (EDA)"
      ],
      "metadata": {
        "id": "V6c03erxyS9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to read the images from folder using opencv"
      ],
      "metadata": {
        "id": "dBQl6gPtyeTe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ULVlznkdvJqB"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "def load_images_from_folder(folder):\n",
        "  \"load_images_from_folder : function loads images from folder ,arg:folder takes list of folder path \"\n",
        "  cv_img = []\n",
        "  cv_label = []\n",
        "  for path in sorted(glob.glob(folder)):\n",
        "    \n",
        "    img= cv2.imread(path)\n",
        "    if img is not None:\n",
        "      cv_img.append(img)\n",
        "      cv_label.append(path)\n",
        "  return cv_img,cv_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RsmnuxZGPDL9"
      },
      "outputs": [],
      "source": [
        "path = \"/content/dataset/*.png\"\n",
        "cv_img,cv_label = load_images_from_folder(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "just checking shape and type of images"
      ],
      "metadata": {
        "id": "hgDcLg_zy9ya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PfcnFR4WpN3"
      },
      "outputs": [],
      "source": [
        "print(len(cv_img),len(cv_label),\"total number of images and labels\")\n",
        "print(\"The shape of the image is camera c10:\", cv2.imread(cv_label[1]).shape)\n",
        "print(\"The shape of the image is camera c20:\", cv2.imread( '/content/dataset/c20-1616783552981.png').shape)\n",
        "print(\"The shape of the image is camera c21:\", cv2.imread(  '/content/dataset/c21_2021_03_25__16_17_55.png').shape)\n",
        "print(\"The shape of the image is camera c23:\", cv2.imread( '/content/dataset/c23-1616689078329.png').shape)\n",
        "\n",
        "type(cv_img[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let me check the shape of all images , since all images not having same dimensions and we begin to take into camera ids and number of images were caputure from it."
      ],
      "metadata": {
        "id": "3F6dbJX7zMtj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TxwS53EO4DJC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "def number_camera(cv_label):\n",
        "  #takes list of labels from image dataset and return camera id and number of images captured from it\n",
        "  camera_id = []\n",
        "  for path in cv_label:\n",
        "    path = path.split(\"/\")\n",
        "    path = path[3]\n",
        "    camera_id.append(path[0:3])\n",
        "  return Counter(camera_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can say that there are 4 camera were used , check the images they were capture "
      ],
      "metadata": {
        "id": "p3ic4aYBzq3C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLvxU4sSvjkb"
      },
      "outputs": [],
      "source": [
        "camera_id = number_camera(cv_label)\n",
        "camera_id\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot bar grah for occurance of images frm each camera id"
      ],
      "metadata": {
        "id": "064FPZBMz3fR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZpqR5-ValH5"
      },
      "outputs": [],
      "source": [
        "plt.bar(camera_id.keys(), camera_id.values())\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we check the image dimensions and plot its occurance\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "X6DGkjbyz_4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZulotF5bljbD"
      },
      "outputs": [],
      "source": [
        "def checking_shape_total(c_img):\n",
        "  #takes list of images of input and returns occurance of each dimensions in dataset\n",
        "  check_shape = []\n",
        "  key = []\n",
        "  value = []\n",
        "  for i,img in enumerate(c_img):\n",
        "    check_shape.append(c_img[i].shape)\n",
        "  count = Counter(check_shape)\n",
        "  vals = list(count.values())\n",
        "  keys = list(count.keys())\n",
        "  for i in keys:\n",
        "    key.append(str(i))\n",
        "  return key,vals\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uFRARbH2oGZs"
      },
      "outputs": [],
      "source": [
        "shape,vals = checking_shape_total(cv_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXq7aw_Zpo9R"
      },
      "outputs": [],
      "source": [
        "plt.bar(shape, vals)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so i checked with images captured by camera ids, so we can group images based on camera ids because of images caputure are different "
      ],
      "metadata": {
        "id": "OvzXgv5E0jYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "and computational and analysis makes it better"
      ],
      "metadata": {
        "id": "9-yqILXD1APq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OYFk71-W6576"
      },
      "outputs": [],
      "source": [
        "def grouping_imges_ids(cv_label,cv_img):\n",
        "  #group images, label based on camera ids becasue each camera captured different images\n",
        "  c10_img = []\n",
        "  c10_path = []\n",
        "  c20_img = []\n",
        "  c20_path = []\n",
        "  c21_img = []\n",
        "  c21_path = []\n",
        "  c23_img = []\n",
        "  c23_path = []\n",
        "  for i, path in enumerate(cv_label):\n",
        "    org = path\n",
        "    path = path.split(\"/\")\n",
        "    path = path[3]\n",
        "    path = path[0:3]\n",
        "    if path == \"c10\":\n",
        "      c10_img.append(cv_img[i])\n",
        "      c10_path.append(org)\n",
        "    if path == \"c20\":\n",
        "      c20_img.append(cv_img[i])  \n",
        "      c20_path.append(org)\n",
        "    if path == \"c21\":\n",
        "      c21_img.append(cv_img[i])  \n",
        "      c21_path.append(org)\n",
        "    if path == \"c23\":\n",
        "      c23_img.append(cv_img[i])\n",
        "      c23_path.append(org)\n",
        "  return c10_img,c20_img,c21_img,c23_img,c10_path,c20_path,c21_path,c23_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "R6bfiCyk8nGm"
      },
      "outputs": [],
      "source": [
        "c10_img,c20_img,c21_img,c23_img,c10_path,c20_path,c21_path,c23_path = grouping_imges_ids(cv_label,cv_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we check the dimension for each camera ids we grouped earlier"
      ],
      "metadata": {
        "id": "LQz7RIIa18WS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tvEXqJEg8wUv"
      },
      "outputs": [],
      "source": [
        "def checking_shape(c_img):\n",
        "  check_shape = []\n",
        "  for i,img in enumerate(c_img):\n",
        "    check_shape.append(c_img[i].shape)\n",
        "  return Counter(check_shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq22yVj77S9-"
      },
      "outputs": [],
      "source": [
        "checking = checking_shape(c10_img)\n",
        "checking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0Qhp7NW7iYR"
      },
      "outputs": [],
      "source": [
        "checking_shape(c20_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3PTvtT-BPQk"
      },
      "outputs": [],
      "source": [
        "checking_shape(c21_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXPofgO589rY"
      },
      "outputs": [],
      "source": [
        "checking_shape(c23_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "scaling the images for fast computation, since we choose 120 * 160 for better, we make all images of eacg grouped images into same"
      ],
      "metadata": {
        "id": "Vnses13946ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "\n",
        "\n",
        "\n",
        "def resize_images(cv_img,w,h):\n",
        "  #takes list images and resize its scale\n",
        "  list_resiz = []\n",
        "  for img in cv_img:\n",
        "    \n",
        "    \n",
        "    resized_image = cv2.resize(img, (w, h))\n",
        "    list_resiz.append(resized_image)\n",
        "  return list_resiz"
      ],
      "metadata": {
        "id": "H-a59Z8GXYKv"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c10_img = resize_images(c10_img,160,120)"
      ],
      "metadata": {
        "id": "ByVITIqhZOb2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c20_img = resize_images(c20_img,160,120)"
      ],
      "metadata": {
        "id": "RNqK8QrvZX9Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c21_img = resize_images(c21_img,160,120)"
      ],
      "metadata": {
        "id": "yYNh1U6tSZ9G"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c23_img = resize_images(c23_img,160,120)"
      ],
      "metadata": {
        "id": "0hqtdhbokj6j"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "since , we looked into dataset I feel we have to take care of glare and lighting effect its main parameter of each images we can see, same background with different light intensity we can th lot of showdow and glare effect."
      ],
      "metadata": {
        "id": "TGDim9vp5iEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for each image , i find out the glare and remove its effect for better comparision.or to find duplicates"
      ],
      "metadata": {
        "id": "elNGAvvs6FUE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MqDbufTCvZa6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "def glare_effect(cv_img):\n",
        "  list_glare = []\n",
        "  # read image\n",
        "  for img in cv_img:\n",
        "        # convert to gray\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # threshold grayscale image to extract glare\n",
        "    mask = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    # use mask with input to do inpainting\n",
        "    result = cv2.inpaint(img, mask, 91, cv2.INPAINT_TELEA) \n",
        "    list_glare.append(result)\n",
        "\n",
        "\n",
        "    # display it\n",
        "    #cv2.imshow(\"IMAGE\", img)\n",
        "    #cv2.imshow(\"GRAY\", gray)\n",
        "    #cv2.imshow(\"MASK\", mask)\n",
        "    #cv2_imshow(result)\n",
        "  return list_glare\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we remove glare and lightning effect from each image using above function, it was really interseting job"
      ],
      "metadata": {
        "id": "vSJV4rpjdkqk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hde5bBXoEzd"
      },
      "outputs": [],
      "source": [
        "c10_img_glare = glare_effect(c10_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1w6tK10NpvA"
      },
      "outputs": [],
      "source": [
        "c20_img_glare = glare_effect(c20_img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c21_img_glare = glare_effect(c21_img)"
      ],
      "metadata": {
        "id": "EfpPxLzfWRgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c23_img_glare = glare_effect(c23_img)"
      ],
      "metadata": {
        "id": "H-fbxulmWRj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c10_img = c10_img_glare\n",
        "c20_img = c20_img_glare\n",
        "c21_img = c21_img_glare\n",
        "c23_img = c23_img_glare"
      ],
      "metadata": {
        "id": "o8wZt1j3NSIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you need to run preprocess_image_change_detection\n",
        "function on comparing images and then run compare_frames_change_detection\n",
        "with a pair of them imaging_interview code was used"
      ],
      "metadata": {
        "id": "J8xexkfbVfUn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jGzgDgUOSXAN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # for image display\n",
        "\n",
        "import imutils\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def draw_color_mask(img, borders, color=(200, 150, 255)):\n",
        "\n",
        "    h = img.shape[0]\n",
        "\n",
        "    w = img.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "    x_min = int(borders[0] * w / 100)\n",
        "\n",
        "    x_max = w - int(borders[2] * w / 100)\n",
        "\n",
        "    y_min = int(borders[1] * h / 100)\n",
        "\n",
        "    y_max = h - int(borders[3] * h / 100)\n",
        "\n",
        "\n",
        "\n",
        "    img = cv2.rectangle(img, (0, 0), (x_min, h), color, -1)\n",
        "\n",
        "    img = cv2.rectangle(img, (0, 0), (w, y_min), color, -1)\n",
        "\n",
        "    img = cv2.rectangle(img, (x_max, 0), (w, h), color, -1)\n",
        "\n",
        "    img = cv2.rectangle(img, (0, y_max), (w, h), color, -1)\n",
        "\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image_change_detection(img, gaussian_blur_radius_list=None, black_mask=(5, 10, 5, 0)):\n",
        "\n",
        "    gray = img.copy()\n",
        "    gray = cv2.cvtColor(gray, cv2.COLOR_BGR2GRAY)\n",
        "    #cv2_imshow(gray)\n",
        "    if gaussian_blur_radius_list is not None:\n",
        "\n",
        "        for radius in gaussian_blur_radius_list:\n",
        "\n",
        "            gray = cv2.GaussianBlur(gray, (radius, radius), 0)\n",
        "\n",
        "\n",
        "\n",
        "    gray = draw_color_mask(gray, black_mask)\n",
        "    #cv2_imshow(gray)\n",
        "\n",
        "\n",
        "    return gray\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compare_frames_change_detection(prev_frame, next_frame, min_contour_area):\n",
        "\n",
        "    frame_delta = cv2.absdiff(prev_frame, next_frame)\n",
        "    #cv2_imshow(prev_frame)\n",
        "    #cv2_imshow(next_frame)\n",
        "    #cv2_imshow(frame_delta)\n",
        "\n",
        "    thresh = cv2.threshold(frame_delta, 120, 255, cv2.THRESH_BINARY)[1]\n",
        "    #cv2_imshow(thresh)\n",
        "\n",
        "\n",
        "    thresh = cv2.dilate(thresh, None, iterations=8)\n",
        "    #cv2_imshow(thresh)\n",
        "\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
        "\n",
        "                            cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "\n",
        "\n",
        "   \n",
        "    score = 0\n",
        "\n",
        "    res_cnts = []\n",
        "\n",
        "    for c in cnts:\n",
        "\n",
        "        if cv2.contourArea(c) < min_contour_area:\n",
        "            continue\n",
        "\n",
        "        res_cnts.append(c)\n",
        "\n",
        "        score += cv2.contourArea(c)\n",
        "\n",
        "\n",
        "\n",
        "    return score, res_cnts, thresh\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we check the function provided by you, by taking example of two images"
      ],
      "metadata": {
        "id": "Z4R7_gNH7B8m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "wxCA1aKgRakx"
      },
      "outputs": [],
      "source": [
        "image1 = preprocess_image_change_detection(c10_img[124],[5])\n",
        "\n",
        "image2 = preprocess_image_change_detection(c10_img[125],[5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "3M7AQgyOSQf_"
      },
      "outputs": [],
      "source": [
        "score, res_cnts, thresh = compare_frames_change_detection(image1,image2,500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUruhMpDSzem",
        "outputId": "11209a3d-9a8b-46cb-fc0b-7d2f11bda5bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720.0"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "xFexGf-sVGns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e876e88a-676e-4aef-c548-451ff9346081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x,y,w,h: 18 24 35 29\n"
          ]
        }
      ],
      "source": [
        "for cntr in res_cnts:\n",
        "    x,y,w,h = cv2.boundingRect(cntr)\n",
        "    cv2.rectangle(thresh, (x, y), (x+w, y+h), (250, 150, 255), 2)\n",
        "    print(\"x,y,w,h:\",x,y,w,h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooQ-NS1d0Jlw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.imshow(thresh)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now , we find duplicate images by find the original images and display it, then will find duplicate"
      ],
      "metadata": {
        "id": "CtqB27Jp_QQw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "dW0KixDwILZf"
      },
      "outputs": [],
      "source": [
        "def find_orginal(list_img,c10_path):\n",
        "  original_list = c10_path.copy()\n",
        "  dupe_list = []\n",
        "  for i in range(len(list_img)-1):\n",
        "    for j in range(i+1,len(list_img)-1):\n",
        "      img1 = preprocess_image_change_detection(list_img[i],[5])\n",
        "      img2 = preprocess_image_change_detection(list_img[j],[5])\n",
        "      score, res_cnts, thresh = compare_frames_change_detection(img1,img2,260)\n",
        "      if score < 250:\n",
        "        a = str(original_list[j])\n",
        "        if a not in dupe_list:\n",
        "          dupe_list.append(a)\n",
        "        original_list[j] = \" \"\n",
        "        \n",
        "  return original_list,dupe_list\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_list_10,dupe_list_10 = find_orginal(c10_img,c10_path)\n",
        "original_list_20,dupe_list_20 = find_orginal(c20_img,c20_path)\n",
        "original_list_21,dupe_list_21 = find_orginal(c21_img,c21_path)\n",
        "original_list_23,dupe_list_23 = find_orginal(c23_img,c23_path)"
      ],
      "metadata": {
        "id": "XCI-1jCwVLQq"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "retain only, path to original image using this we get duplicates list"
      ],
      "metadata": {
        "id": "fH-jfy-__FTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_list(original_list):\n",
        "  orginal_clean_list = []\n",
        "  for i in original_list:\n",
        "    if i != \" \":\n",
        "      orginal_clean_list.append(i)\n",
        "  return original_list"
      ],
      "metadata": {
        "id": "ssTZ2UODqWfm"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_list_10 = clean_list(original_list_10)\n",
        "original_list_20 = clean_list(original_list_20)\n",
        "original_list_21 = clean_list(original_list_21)\n",
        "original_list_23 = clean_list(original_list_23)"
      ],
      "metadata": {
        "id": "hZdsvxhRu_Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_original(orginal_clean_list):\n",
        "  for i in orginal_clean_list:\n",
        "    r = cv2.imread(i)\n",
        "    cv2_imshow(r)"
      ],
      "metadata": {
        "id": "eqKykUiQwezD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_original(original_list_10)\n",
        "display_original(original_list_20)\n",
        "display_original(original_list_21)\n",
        "display_original(original_list_23)"
      ],
      "metadata": {
        "id": "ORhaFNlp9zRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get duplicate list taking difference original list and image list"
      ],
      "metadata": {
        "id": "R6sfaF-T-7CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c10_list = list(set(c10_path) - set(original_list_10))\n",
        "c20_list = list(set(c20_path) - set(original_list_20))\n",
        "c21_list = list(set(c21_path) - set(original_list_21))\n",
        "c23_list = list(set(c23_path) - set(original_list_23))\n"
      ],
      "metadata": {
        "id": "xPGEO0t-vdMG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "delete duplicates from the folder, sing duplicate list, yeeeeeeees did it"
      ],
      "metadata": {
        "id": "0GFyp8eE-1ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def delete_dups(c_list):\n",
        "  for i in c_list:\n",
        "    os.remove(i)"
      ],
      "metadata": {
        "id": "STpUZa5WvxEU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_dups(c10_list)\n",
        "delete_dups(c20_list)\n",
        "delete_dups(c21_list)\n",
        "delete_dups(c23_list)"
      ],
      "metadata": {
        "id": "EJlpF0Wbd4aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wqNdXqt-KshQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Kopernikus_rahul.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}